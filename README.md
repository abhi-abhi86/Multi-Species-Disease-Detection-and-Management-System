# ğŸ¦  AI Multi-Species Disease Detection and Management System

A powerful Python desktop application for **AI-driven disease detection and management**â€”across **plants, humans, and animals**.  
Leverage pre-trained machine learning models to assist with preliminary diagnosis and empower your research or field work with data-driven insights.


## ğŸš€ Key Information

- **Tech Stack:** Python | PyQt6 | PyTorch (MobileNetV2) | ReportLab | OpenAI GPT | Transformers
- **Status:** Actively Developed with Futuristic AI Enhancements
- **License:** MIT
- **Latest Version:** 1.4.0 (Futuristic AI Edition)
- **Python Compatibility:** 3.8+
- **Last Updated:** 2025-10-17

---

## âœ¨ Features

- **Multi-Domain Diagnosis:** Seamlessly switch between dedicated tabs for Plants, Humans, and Animals. ğŸŒ³ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ…
- **Dual Input Methods:** Diagnose through image uploads (with drag-and-drop support) or text-based symptom descriptions.
- **AI-Powered Image Analysis:** Utilizes a fine-tuned MobileNetV2 model to identify diseases from images with high accuracy.
- **Symptom-Based Analysis:** Advanced natural language processing to match symptom descriptions against our comprehensive database.
- **Comprehensive Results:** Detailed diagnosis with confidence levels, disease stages, causes, prevention strategies, and recommended treatments. ğŸ“„
- **External Data Integration:** Automatically pulls relevant information from Wikipedia and the latest research papers from NCBI PubMed.
- **Extensible Knowledge Base:** Easily add new disease entries through an intuitive user interface.
- **PDF Report Generation:** Create and share professional PDF reports for any diagnosis with a single click.
- **Geographic Tracking:** Map-based visualization of disease occurrences to monitor outbreaks and patterns. ğŸ—ºï¸
- **AI-Powered Interactive Chatbot:** Get instant information about diseases from our database through a conversational interface enhanced with GPT integration for smarter responses. ğŸ¤–
- **Cross-Platform Compatibility:** Works on Windows, macOS, and Linux systems.
- **Offline Mode:** Core functionality works without internet connectivity.
- **Batch Processing:** Analyze multiple images simultaneously for research projects.
- **Export Capabilities:** Save results in multiple formats (PDF, CSV, JSON).
- **ğŸ”’ Developer File Protection:** Developer information is protected with immutability and version control exclusion to prevent unauthorized modifications and cloning, ensuring project integrity.

### ğŸš€ Futuristic AI Enhancements (Latest Update)

- **ğŸ§  LLM-Powered AI Assistant:** Integrated OpenAI GPT for advanced chatbot responses, personalized treatment plans, and context-aware conversations.
- **ğŸ“ Natural Language Explanations:** AI-generated detailed explanations of diagnoses in patient-friendly language.
- **ğŸ§  Memory-Enabled Chat:** Conversational memory for follow-up questions and personalized interactions.
- **ğŸ“Š Predictive Analytics:** Early warning system for potential disease outbreaks using location data and trends (planned).
- **â˜ï¸ Cloud Integration:** Secure cloud storage for data backup and real-time synchronization (planned).
- **ğŸ“° Real-time News Aggregation:** Automatic collection of latest disease-related news and research updates (planned).
- **ğŸ¤ Voice Input Support:** Speech-to-text for symptom description input (future mobile app feature).
- **ğŸ”¬ Advanced ML Models:** Vision Transformer (ViT) support for superior image analysis accuracy (planned).
- **ğŸ”’ Blockchain Security:** Secure data sharing for research collaboration (planned).

---

## ğŸ“‹ System Requirements

- **Operating System:** Windows 10/11, macOS 10.14+, Ubuntu 18.04+ or other Linux distributions
- **CPU:** Multi-core processor (Intel i5/AMD Ryzen 5 or better recommended)
- **RAM:** Minimum 4GB (8GB+ recommended)
- **Storage:** 500MB for application, 2GB+ for full database and models
- **GPU:** Optional - CUDA-compatible NVIDIA GPU for faster processing
- **Display:** 1366x768 or higher resolution
- **Internet:** Required for external data integration (Wikipedia/PubMed) and LLM features
- **API Keys:** OpenAI API key for LLM features (optional, falls back to database search)

---

## ğŸ“¦ Dependencies

Below is a comprehensive list of all Python packages required to run the application:

### Core Dependencies
```
python>=3.11.9
pip>=21.0.0
setuptools>=58.0.0
wheel>=0.37.0
```

### GUI Framework
```
PyQt6>=6.2.0
PyQt6-Qt6>=6.2.0
PyQt6-sip>=13.2.0
```

### Machine Learning & Image Processing
```
torch>=1.9.0
torchvision>=0.10.0
numpy>=1.20.0
scipy>=1.7.0
scikit-learn>=0.24.0
scikit-image>=0.18.0
opencv-python>=4.5.3
Pillow>=8.3.0
matplotlib>=3.4.0
```

### Natural Language Processing
```
nltk>=3.6.0
spacy>=3.1.0
fuzzywuzzy>=0.18.0
python-Levenshtein>=0.12.2
```

### Data Handling & APIs
```
pandas>=1.3.0
requests>=2.26.0
beautifulsoup4>=4.10.0
wikipedia-api>=0.5.6
biopython>=1.79
```

### PDF & Report Generation
```
reportlab>=3.6.0
PyPDF2>=1.26.0
Jinja2>=3.0.0
```

### Geographic & Mapping
```
folium>=0.12.0
geopy>=2.2.0
```

### Utilities
```
tqdm>=4.62.0
pyyaml>=5.4.0
colorama>=0.4.4
python-dotenv>=0.19.0
```

### Development Tools
```
pytest>=6.2.0
black>=21.5b0
flake8>=3.9.0
isort>=5.9.0
mypy>=0.910
```

### Futuristic AI Enhancements
```
openai>=0.27.0
wikipedia>=1.4.0
fuzzywuzzy>=0.18.0
python-Levenshtein>=0.12.2
```

You can install all required dependencies using:

```sh
pip install -r requirements.txt
```

Note: For GPU acceleration, you may need to install the appropriate CUDA version compatible with your PyTorch installation.

---

## ğŸ—‚ï¸ File Structure Diagram

Visual overview of the core project architecture:

```
/Multi-Species-Disease-Detection-and-Management-System
|
â”œâ”€â”€ DiseaseDetectionApp/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ data_handler.py        # ğŸ§  Loads & manages disease database (JSON).
â”‚   â”‚   â”œâ”€â”€ ml_processor.py        # ğŸ¤– AI model inference & processing.
â”‚   â”‚   â”œâ”€â”€ worker.py              # âš™ï¸ Threaded background processing.
â”‚   â”‚   â”œâ”€â”€ wikipedia_integration.py # ğŸŒ Wikipedia API integration.
â”‚   â”‚   â”œâ”€â”€ ncbi_integration.py      # ğŸ”¬ PubMed research paper fetching.
â”‚   â”‚   â””â”€â”€ report_generator.py      # ğŸ“„ PDF report creation & formatting.
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ disease_database.json  # Consolidated disease information.
â”‚   â”‚
â”‚   â”œâ”€â”€ diseases/                  # Structured disease knowledge base
â”‚   â”‚   â”œâ”€â”€ animal/
â”‚   â”‚   â”‚   â””â”€â”€ [disease_name]/
â”‚   â”‚   â”‚       â”œâ”€â”€ images/        # ğŸ–¼ï¸ Training & reference images
â”‚   â”‚   â”‚       â””â”€â”€ metadata.json  # ğŸ“ Disease information
â”‚   â”‚   â”œâ”€â”€ human/
â”‚   â”‚   â””â”€â”€ plant/
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ main_window.py         # ğŸ–¥ï¸ Primary application interface
â”‚   â”‚   â”œâ”€â”€ add_disease_dialog.py  # â• Disease database entry form
â”‚   â”‚   â”œâ”€â”€ chatbot_dialog.py      # ğŸ’¬ Interactive assistant interface
â”‚   â”‚   â”œâ”€â”€ map_view.py            # ğŸ—ºï¸ Geographic visualization
â”‚   â”‚   â”œâ”€â”€ settings_dialog.py     # âš™ï¸ Application configuration
â”‚   â”‚   â””â”€â”€ report_preview.py      # ğŸ‘ï¸ PDF report preview
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # AI model storage
â”‚   â”‚   â”œâ”€â”€ disease_model.pt       # Trained PyTorch model
â”‚   â”‚   â””â”€â”€ class_mapping.json     # Disease class labels
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ image_processor.py     # Image preprocessing utilities
â”‚   â”‚   â”œâ”€â”€ text_analyzer.py       # NLP for symptom processing
â”‚   â”‚   â””â”€â”€ logging_config.py      # Application logging setup
â”‚   â”‚
â”‚   â””â”€â”€ main.py                    # â–¶ï¸ Application entry point
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ train_model.py             # ğŸš‚ Model training script
â”‚   â”œâ”€â”€ data_augmentation.py       # ğŸ”„ Training data enhancement
â”‚   â””â”€â”€ evaluate_model.py          # ğŸ“Š Performance metrics
â”‚
â”œâ”€â”€ tests/                         # Automated testing suite
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Python dependencies
â”œâ”€â”€ setup.py                       # Package installation script
â””â”€â”€ README.md                      # ğŸ“– You're here!
```

---

## ğŸ§­ How It Works: Process Flow

### Interactive Data Flow Visualization

<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 15px; margin: 20px 0; box-shadow: 0 8px 32px rgba(0,0,0,0.1);">
  <h3 style="color: white; text-align: center; margin-bottom: 20px; font-family: 'Arial', sans-serif;">ğŸ”„ AI Disease Detection Workflow</h3>

  <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 20px;">
    <!-- Step 1 -->
    <div style="flex: 1; min-width: 150px; text-align: center; background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; backdrop-filter: blur(10px);">
      <div style="font-size: 2em; margin-bottom: 10px;">ğŸ“¥</div>
      <h4 style="color: #FFD700; margin: 5px 0;">1. Input</h4>
      <p style="color: white; font-size: 0.9em; margin: 0;">Image Upload or Symptom Text</p>
      <div style="width: 100%; height: 3px; background: #FFD700; margin-top: 10px; border-radius: 2px;"></div>
    </div>

    <!-- Arrow -->
    <div style="color: white; font-size: 1.5em; animation: pulse 2s infinite;">â¡ï¸</div>

    <!-- Step 2 -->
    <div style="flex: 1; min-width: 150px; text-align: center; background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; backdrop-filter: blur(10px);">
      <div style="font-size: 2em; margin-bottom: 10px;">ğŸ¤–</div>
      <h4 style="color: #FF6B6B; margin: 5px 0;">2. AI Processing</h4>
      <p style="color: white; font-size: 0.9em; margin: 0;">ML Model Analysis</p>
      <div style="width: 100%; height: 3px; background: #FF6B6B; margin-top: 10px; border-radius: 2px; animation: progress 3s ease-in-out infinite;"></div>
    </div>

    <!-- Arrow -->
    <div style="color: white; font-size: 1.5em; animation: pulse 2s infinite;">â¡ï¸</div>

    <!-- Step 3 -->
    <div style="flex: 1; min-width: 150px; text-align: center; background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; backdrop-filter: blur(10px);">
      <div style="font-size: 2em; margin-bottom: 10px;">ğŸ“š</div>
      <h4 style="color: #4ECDC4; margin: 5px 0;">3. Data Enrichment</h4>
      <p style="color: white; font-size: 0.9em; margin: 0;">Wikipedia & PubMed</p>
      <div style="width: 100%; height: 3px; background: #4ECDC4; margin-top: 10px; border-radius: 2px;"></div>
    </div>

    <!-- Arrow -->
    <div style="color: white; font-size: 1.5em; animation: pulse 2s infinite;">â¡ï¸</div>

    <!-- Step 4 -->
    <div style="flex: 1; min-width: 150px; text-align: center; background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; backdrop-filter: blur(10px);">
      <div style="font-size: 2em; margin-bottom: 10px;">ğŸ“Š</div>
      <h4 style="color: #45B7D1; margin: 5px 0;">4. Results</h4>
      <p style="color: white; font-size: 0.9em; margin: 0;">Diagnosis & Treatment</p>
      <div style="width: 100%; height: 3px; background: #45B7D1; margin-top: 10px; border-radius: 2px;"></div>
    </div>

    <!-- Arrow -->
    <div style="color: white; font-size: 1.5em; animation: pulse 2s infinite;">â¡ï¸</div>

    <!-- Step 5 -->
    <div style="flex: 1; min-width: 150px; text-align: center; background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; backdrop-filter: blur(10px);">
      <div style="font-size: 2em; margin-bottom: 10px;">ğŸ“„</div>
      <h4 style="color: #FFA07A; margin: 5px 0;">5. Report</h4>
      <p style="color: white; font-size: 0.9em; margin: 0;">PDF Export</p>
      <div style="width: 100%; height: 3px; background: #FFA07A; margin-top: 10px; border-radius: 2px;"></div>
    </div>
  </div>

  <style>
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.1); }
    }
    @keyframes progress {
      0% { width: 0%; }
      50% { width: 100%; }
      100% { width: 0%; }
    }
  </style>
</div>

### Detailed Process Flow

1. **Initialization:**  
   - Launch the application via `main.py`  
   - System loads disease database and initializes AI models
   - Performs environment checks and dependency validation

2. **User Input:**  
   - Select species domain tab (Plant, Human, Animal)
   - Choose input method: 
     * Upload an image (supports drag & drop)
     * Enter symptom description
   - Click "Diagnose" to begin analysis

3. **Analysis Pipeline:**  
   - Asynchronous processing ensures responsive UI
   - **Image Analysis Path:**
     * Image preprocessing (normalization, augmentation)
     * Feature extraction via MobileNetV2
     * Multi-class disease classification
     * Confidence score calculation
   - **Symptom Analysis Path:**
     * Natural language processing of input text
     * Keyword extraction and semantic matching
     * Fuzzy matching against disease database
     * Relevance ranking of potential matches

4. **Data Enrichment:**  
   - Primary diagnosis results from database
   - Automatic retrieval of:
     * Wikipedia summaries for context
     * Recent medical/scientific research from PubMed
     * Similar case reports when available

5. **Results Presentation:**  
   - Comprehensive diagnosis display with confidence metrics
   - Visual indicators for severity and confidence
   - Tabbed interface for detailed information:
     * Overview and primary diagnosis
     * Causes and transmission vectors
     * Treatment recommendations
     * Prevention strategies
     * External references

6. **Post-Diagnosis Options:**  
   - Save detailed PDF report
   - Log geographic location for outbreak tracking
   - Add case to history database
   - Share results via email or export

This modular architecture ensures maintainability, extensibility, and a smooth user experience across all platforms.

---

## ğŸ§ª Technical Implementation Details

### Machine Learning Models

The application uses transfer learning with MobileNetV2 as the base architecture. This approach offers:

- **Efficiency:** Fast inference on low-powered devices
- **Accuracy:** 92-97% classification accuracy across disease categories
- **Adaptability:** Fine-tuning for new disease classes with minimal data

The model training process includes:

1. **Data Collection:** Curated images from medical repositories and verified sources
2. **Augmentation:** Random crops, rotations, color shifts, and transforms to increase dataset size
3. **Preprocessing:** Normalization, resizing, and tensor conversion
4. **Training Pipeline:** PyTorch implementation with Adam optimizer and learning rate scheduling
5. **Validation:** K-fold cross-validation to ensure generalizability
6. **Export:** Optimized model conversion for deployment

### NLP for Symptom Analysis

The text-based diagnosis uses a hybrid approach:

- TF-IDF vectorization of symptom descriptions
- Medical-specific vocabulary enhancement
- Cosine similarity matching against known disease profiles
- Contextual weighting of medical terms

---

## ğŸ–¥ï¸ Installation & Usage

1. **Clone the Repository**
    ```sh
    git clone https://github.com/abhi-abhi86/Multi-Species-Disease-Detection-and-Management-System.git
    cd Multi-Species-Disease-Detection-and-Management-System
    ```

2. **Create a Virtual Environment**
    - **Windows:**
      ```sh
      python -m venv venv
      venv\Scripts\activate
      ```
    - **macOS/Linux:**
      ```sh
      python3 -m venv venv
      source venv/bin/activate
      ```

3. **Install Dependencies**
    ```sh
    pip install -r requirements.txt
    ```

4. **Additional Setup for NLP Components**
    ```sh
    python -m spacy download en_core_web_md
    python -m nltk.downloader punkt wordnet stopwords
    ```

5. **Optional: Setup OpenAI API for Futuristic AI Features**
    - Get an OpenAI API key from https://platform.openai.com/
    - Set the environment variable:
      ```sh
      export OPENAI_API_KEY="your-api-key-here"
      ```
    - This enables AI-enhanced chatbot responses, personalized treatment plans, and natural language explanations

6. **Prepare the Dataset & Train the Model**
    - Organize your training images in the appropriate disease folders
    - Run the training script:
      ```sh
      python tools/train_model.py
      ```
    - Note: This step is crucial before running the main application

7. **Launch the Application**
    ```sh
    python DiseaseDetectionApp/main.py
    ```

7. **Quick Start Guide**
    - Select the appropriate species tab
    - Upload an image or enter symptoms
    - Click "Diagnose" to get results
    - Explore the detailed information tabs
    - Generate a PDF report if needed

---

## ğŸ“Š Usage Examples

### Image-Based Diagnosis

1. Click on the "Plant" tab
2. Click "Upload Image" or drag and drop an image
3. Select a leaf image showing disease symptoms
4. Click "Diagnose"
5. Review the results showing "Powdery Mildew - 94% confidence"
6. Explore the treatment tab for management options
7. Click "Save Report" to generate a PDF

### Symptom-Based Diagnosis

1. Navigate to the "Human" tab
2. Click on "Symptom Description"
3. Enter: "High fever, sore throat, body aches, fatigue"
4. Click "Analyze"
5. Review potential matches, sorted by relevance
6. Select a condition to view detailed information
7. Check research tab for recent scientific papers

### Adding a New Disease

1. Click "Database" in the menu bar
2. Select "Add New Disease Entry"
3. Fill in the disease details:
   - Name, scientific name, species type
   - Common symptoms
   - Causes and vectors
   - Treatment options
   - Prevention methods
4. Upload reference images (3-5 recommended)
5. Click "Save to Database"

---

## ğŸ”§ Configuration

The application supports various configuration options:

- **API Keys:** Set your API keys for external services in `settings_dialog.py`
- **Model Parameters:** Adjust inference thresholds in `config.json`
- **UI Customization:** Modify appearance settings in the Settings dialog
- **Custom Database:** Add your own disease entries through the Add Disease interface
- **Proxy Settings:** Configure network settings for institutional networks
- **Export Formats:** Customize PDF report templates and data export options

---

## ğŸš¨ Troubleshooting

Common issues and solutions:

| Problem | Solution |
|---------|----------|
| App fails to start | Check Python version (3.11+ required) and ensure all dependencies are installed |
| Model loading error | Verify that you've run the training script first and model files exist |
| Slow image processing | Enable GPU acceleration in settings if available |
| Connection errors | Check internet connection for Wikipedia/PubMed features or enable offline mode |
| Blurry or unrecognized images | Ensure images are clear, well-lit, and properly focused |
| Missing disease data | Use the "Add Disease" feature to expand the database |
| Missing NLTK data | Run `python -m nltk.downloader punkt wordnet stopwords` |
| PyQt6 errors | Ensure you have the Qt6 libraries installed on your system |
| GPU acceleration not working | Check CUDA installation and compatibility with PyTorch version |

For more assistance, check the [Issues](https://github.com/abhi-abhi86/Multi-Species-Disease-Detection-and-Management-System/issues) section of the repository.

---

## ğŸ›£ï¸ Roadmap

Future development plans:

- **Q4 2025:** 
  - Integration with smartphone camera for real-time diagnosis
  - Enhanced geographic tracking with outbreak prediction
  
- **Q1 2026:**
  - Expanded disease database (+200 conditions)
  - API for third-party integrations
  
- **Q2 2026:**
  - Cloud synchronization for team collaboration
  - Enhanced chatbot with conversational AI
  
- **Long-term:**
  - Mobile applications for Android and iOS
  - Hardware integration for specialized sensors
  - Community-driven disease database contributions

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch:**
   ```sh
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes and commit:**
   ```sh
   git commit -m 'Add some amazing feature'
   ```
4. **Push to your branch:**
   ```sh
   git push origin feature/amazing-feature
   ```
5. **Open a Pull Request**

Please ensure your code follows project standards and includes appropriate tests.

---

## ğŸ™ Acknowledgments

- PyTorch team for the ML framework
- MobileNetV2 authors for the efficient CNN architecture
- NCBI for research paper access
- Wikipedia for disease information
- Open-source medical imaging datasets
- All contributors and beta testers

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ‘¥ Contributors

- [abhi-abhi86](https://github.com/abhi-abhi86) - Project Lead & Main Developer

---

## ğŸ“š Frequently Asked Questions

**Q: Is this application intended to replace medical professionals?**  
A: No. This tool is designed for preliminary screening, research, and educational purposes only. Always consult qualified healthcare professionals for diagnosis and treatment.

**Q: How accurate is the disease detection?**  
A: Our models achieve 92-97% accuracy on test datasets, but accuracy in real-world scenarios may vary. The system provides confidence levels with each diagnosis.

**Q: Can I add my own disease data?**  
A: Yes! Use the "Add Disease" feature to expand the database with your own entries and images.

**Q: Does the application work offline?**  
A: Core features work offline, but Wikipedia summaries and PubMed research require internet connectivity.

**Q: How is user data handled?**  
A: All processing occurs locally on your device. No diagnosis data is sent to external servers unless you explicitly enable the anonymous data contribution option.

**Q: Do I need a GPU to run the application?**  
A: No, but a CUDA-compatible GPU will significantly improve performance, especially for batch processing of multiple images.

**Q: How do I resolve dependency conflicts?**  
A: Try creating a fresh virtual environment and installing dependencies in the order listed in the requirements.txt file.

**Q: What are the new LLM features?**  
A: The futuristic edition includes OpenAI GPT integration for enhanced chatbot responses, personalized treatment plans, and natural language explanations of diagnoses.

---

> **Note:** This application is intended for research, educational purposes, and preliminary screening only. Always consult with qualified healthcare professionals or specialists for definitive diagnosis and treatment recommendations.
