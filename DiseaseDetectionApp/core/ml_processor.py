# DiseaseDetectionApp/core/ml_processor.py
import torch
import os
import json
import re
from PIL import Image
from torchvision import models, transforms
from core.wikipedia_integration import get_wikipedia_summary

# --- Constants ---
# Define paths relative to this file's location to ensure they work correctly.
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, '..', 'disease_model.pt')
CLASS_MAP_PATH = os.path.join(BASE_DIR, '..', 'class_to_name.json')
IMG_SIZE = 224

def get_custom_labels():
    """
    Loads the class-to-name mapping generated by the training script.
    This file links the model's output index to a human-readable disease name.
    """
    if not os.path.exists(CLASS_MAP_PATH):
        print(f"FATAL ERROR: Class mapping file not found at '{CLASS_MAP_PATH}'.")
        print("Please run 'train_disease_classifier.py' to create it.")
        return None
    try:
        with open(CLASS_MAP_PATH, 'r', encoding='utf-8') as f:
            class_to_name = json.load(f)
        # The JSON keys are strings, but the model outputs indices (integers).
        # We convert the keys to integers for correct lookup.
        return {int(k): v for k, v in class_to_name.items()}
    except (json.JSONDecodeError, Exception) as e:
        print(f"Error reading or parsing class mapping file: {e}")
        return None

class MLProcessor:
    """
    Handles loading the custom-trained disease detection model and running predictions.
    This class is specifically designed to use the model generated by `train_disease_classifier.py`.
    """
    def __init__(self):
        print("Initializing custom AI model processor...")
        self.labels = get_custom_labels()
        self.model = None

        if not self.labels:
            print("Could not initialize MLProcessor because class labels are missing.")
            return

        print(f"Found {len(self.labels)} classes: {list(self.labels.values())}")

        # 1. Initialize the model architecture (MobileNetV2).
        #    We use `weights=None` because we are loading our own custom-trained weights.
        self.model = models.mobilenet_v2(weights=None)

        # 2. CRITICAL: Modify the final layer (classifier) of the model.
        #    It must have the same number of outputs as the number of disease classes
        #    you trained it on.
        num_classes = len(self.labels)
        self.model.classifier[1] = torch.nn.Linear(self.model.last_channel, num_classes)

        # 3. Load the trained weights from the .pt file.
        if not os.path.exists(MODEL_PATH):
            print(f"FATAL ERROR: Custom model file not found at '{MODEL_PATH}'.")
            print("Please run 'train_disease_classifier.py' to train and save the model.")
            self.model = None # Disable the model if the file is missing.
            return

        try:
            # Load the saved weights into the model architecture.
            # `map_location='cpu'` ensures it works on computers without a GPU.
            self.model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
            self.model.eval()  # Set the model to evaluation mode (important for accurate predictions).
            print("Custom disease detection model loaded successfully.")
        except Exception as e:
            print(f"An error occurred while loading the model state dictionary: {e}")
            self.model = None

        # 4. Define the image transformation pipeline.
        #    This must be identical to the one used during training for correct results.
        self.transform = transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def predict_from_image(self, image_path, domain, database):
        """
        Analyzes an image using the custom-trained model and returns the diagnosis.
        """
        if not self.model:
            return None, 0, "The AI model is not loaded. Please ensure the model file exists and the training script has been run.", "Error"

        try:
            # Open the image file and ensure it's in RGB format.
            img = Image.open(image_path).convert('RGB')
            
            # Apply the transformations and prepare the image for the model.
            img_t = self.transform(img)
            batch_t = torch.unsqueeze(img_t, 0)

            # Get predictions from the model.
            with torch.no_grad():
                logits = self.model(batch_t)
                # Apply softmax to convert model outputs (logits) into probabilities.
                probabilities = torch.nn.functional.softmax(logits, dim=1)[0]
                
                # Find the highest probability and its corresponding class index.
                confidence_tensor, top_idx_tensor = torch.max(probabilities, 0)
                predicted_idx = top_idx_tensor.item()
                confidence = confidence_tensor.item()
                
                # Look up the disease name using the predicted index.
                predicted_class_name = self.labels.get(predicted_idx, "Unknown Disease")
                
            print(f"AI Model Prediction: '{predicted_class_name}' with {confidence:.2%} confidence.")

            # Find the full disease details from the main database.
            # We match the predicted name against the "name" field in our JSON files.
            best_match_disease = next(
                (d for d in database if d.get("name", "").lower() == predicted_class_name.lower()),
                None
            )

            if best_match_disease:
                final_confidence_pct = confidence * 100
                wiki_summary = get_wikipedia_summary(best_match_disease['name'])
                # Since the model only predicts the disease, we provide a generic stage.
                predicted_stage = "Detected from Image"
                return best_match_disease, final_confidence_pct, wiki_summary, predicted_stage
            else:
                error_msg = f"The AI identified '{predicted_class_name}', but no matching entry was found in the application's database. Ensure the dataset folder names match the disease names in the `.json` files."
                return None, 0, error_msg, "Database Mismatch"

        except FileNotFoundError:
            return None, 0, f"The image file could not be found at: {image_path}", "File Error"
        except Exception as e:
            print(f"An unexpected error occurred during image prediction: {e}")
            return None, 0, f"An error occurred while processing the image: {e}", "Processing Error"

def predict_from_symptoms(symptoms, domain, database):
    """
    Predicts a disease based on text symptoms using robust keyword matching.
    """
    # Filter the database for diseases relevant to the current domain (Plant, Human, etc.).
    domain_candidates = [d for d in database if d.get("domain", "").lower() == domain.lower()]
    if not domain_candidates:
        return None, 0, f"No diseases found in the database for the '{domain}' domain.", "Not applicable"

    # Define common, non-specific words to ignore for better matching.
    stop_words = {'disease', 'symptom', 'issue', 'problem', 'affecting', 'my', 'the', 'a', 'is', 'it', 'plant', 'human', 'animal', 'skin', 'leaf'}
    
    # Extract unique, meaningful keywords from the user's input.
    user_symptoms_set = set(re.findall(r'\b\w+\b', symptoms.lower()))
    meaningful_symptoms = user_symptoms_set - stop_words

    if not meaningful_symptoms:
        return None, 0, "Please provide more specific symptoms. Generic terms are not sufficient for a diagnosis.", "Not applicable"

    best_match, max_score = None, 0
    for disease in domain_candidates:
        # Create a comprehensive text block for each disease to match against.
        disease_text = (
            disease.get('name', '') + ' ' +
            disease.get('description', '') + ' ' +
            ' '.join(disease.get('stages', {}).values()) + ' ' +
            disease.get('causes', '')
        ).lower()
        disease_words = set(re.findall(r'\b\w+\b', disease_text))
        
        # Calculate score based on the number of matching keywords.
        score = len(meaningful_symptoms.intersection(disease_words))
        
        if score > max_score:
            max_score = score
            best_match = disease

    if best_match and max_score > 0:
        # Calculate a simple confidence score.
        confidence = min((max_score / len(meaningful_symptoms)) * 100, 100.0)
        wiki_summary = get_wikipedia_summary(best_match['name'])
        predicted_stage = "Inferred from Symptoms"
        return best_match, confidence, wiki_summary, predicted_stage
    
    return None, 0, "Could not find a matching disease for the specified symptoms.", "Not applicable"
